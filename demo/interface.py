import io
import streamlit as st
import pandas as pd
import numpy as np
import faiss
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer
from transformers import pipeline
from sklearn.metrics.pairwise import cosine_similarity

# â”€â”€â”€ CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_CSV       = "data/main-data/synthetic-resumes.csv"
EMBED_MODEL    = "all-MiniLM-L6-v2"
GEN_MODELS     = ["distilgpt2", "gpt2", "gpt2-medium"]
DEFAULT_GEN    = "distilgpt2"
TOP_K          = 5
MAX_NEW_TOKENS = 128
TEMPERATURE    = 0.7

# â”€â”€â”€ MESSAGES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
welcome_message = """
#### Introduction ğŸš€

This is a simple RAG pipeline for resume screening.  
Enter a Job Description, optionally upload your own resume,  
and click **Run** to see:

- A **match score** between your uploaded resume and the JD  
- A **ranked list** of existing resumes in our corpus  
- A concise **recommendation** generated by a local model
"""

info_message = """
# Information

### 1. Use your own resumes?
Upload a PDF or TXT file above. Weâ€™ll extract the text and compute a match score.

### 2. Retrieval modes
- **Generic RAG**: one-pass FAISS lookup on the full JD.  
- **Fusion RAG**: splits the JD into subâ€‘queries, retrieves each, then fuses their scores.

### 3. Model choices
Pick a small model (`distilgpt2`) for speed or larger ones (`gpt2-medium`) for quality.

### 4. Data privacy
Everything runs **locally**â€”no API keys or external calls.
"""

about_message = """
# About

This demo is part of a RAG-based Resume Screening project.  
It uses:

- **Sentenceâ€‘Transformers** for embeddings (allâ€‘MiniLMâ€‘L6â€‘v2)  
- **FAISS** for fast similarity search  
- **Hugging Face** textâ€‘generation models for recommendations

Source & feedback:  
https://github.com/AbBasitMSU/SmartCandidate-Analyzer-RAG-Based-Resume-Screening  
"""

# â”€â”€â”€ PAGE SETUP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Resume Screening RAG Demo", layout="wide")
st.title("ğŸ“„ SmartCandidate Analyzer (Simple RAG)")

st.markdown(welcome_message)

# â”€â”€â”€ SIDEBAR CONTROLS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode         = st.sidebar.radio("Retrieval Mode", ["Generic RAG", "Fusion RAG"])
model_choice = st.sidebar.selectbox("Answer Model", GEN_MODELS, index=GEN_MODELS.index(DEFAULT_GEN))
uploaded_pdf = st.sidebar.file_uploader("Upload your resume (PDF or TXT)", type=["pdf", "txt"])
st.sidebar.markdown("---")
st.sidebar.markdown(info_message)
st.sidebar.markdown("---")
st.sidebar.markdown(about_message)

# â”€â”€â”€ UTILITY FUNCTIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_resumes(path):
    df = pd.read_csv(path)
    df["ID"] = df["ID"].astype(str)
    embedder = SentenceTransformer(EMBED_MODEL)
    texts = df["Resume"].tolist()
    embs = embedder.encode(texts, convert_to_numpy=True, show_progress_bar=False)
    embs = embs / np.linalg.norm(embs, axis=1, keepdims=True)
    dim = embs.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(embs)
    return df, embedder, index

def extract_text(file) -> str:
    if file.type == "application/pdf":
        reader = PdfReader(io.BytesIO(file.read()))
        return "\n\n".join(page.extract_text() or "" for page in reader.pages)
    else:
        return file.read().decode("utf-8")

@st.cache_resource
def get_generator(model_name):
    gen = pipeline(
        "text-generation",
        model=model_name,
        max_new_tokens=MAX_NEW_TOKENS,
        temperature=TEMPERATURE,
        truncation=True,
        pad_token_id=None,
        device=-1
    )
    gen.tokenizer.pad_token_id = gen.tokenizer.eos_token_id
    return gen

def compute_match_score(jd: str, resume: str, embedder) -> float:
    vecs = embedder.encode([jd, resume], convert_to_numpy=True)
    vecs = vecs / np.linalg.norm(vecs, axis=1, keepdims=True)
    return float(cosine_similarity([vecs[0]], [vecs[1]])[0,0])

def retrieve_indices(query: str, mode: str, embedder, index) -> list[int]:
    qv = embedder.encode([query], convert_to_numpy=True)
    qv = qv / np.linalg.norm(qv, keepdims=True)
    if mode == "Generic RAG":
        _, inds = index.search(qv, TOP_K)
        return inds[0].tolist()
    # Fusion RAG
    subs = query.split('.')[:4]
    scores = {}
    for chunk in [query] + subs:
        cv = embedder.encode([chunk], convert_to_numpy=True)
        cv = cv / np.linalg.norm(cv, keepdims=True)
        _, inds = index.search(cv, TOP_K)
        for rank, idx in enumerate(inds[0]):
            scores[idx] = scores.get(idx, 0) + 1.0/(rank+1)
    fused = sorted(scores.items(), key=lambda x: -x[1])[:TOP_K]
    return [idx for idx,_ in fused]

def generate_recommendation(jd: str, indices: list[int], df, generator) -> str:
    context = "\n\n".join(
        f"Applicant ID {df.iloc[i]['ID']}:\n{df.iloc[i]['Resume'][:200]}â€¦"
        for i in indices
    )
    prompt = f"""
You are an expert recruiter. Recommend the best candidate by Applicant ID and brief reason.

Job Description:
{jd}

Resumes:
{context}

Answer:
"""
    out = generator(prompt)[0]["generated_text"]
    return out.replace(prompt, "").strip()

# â”€â”€â”€ LOAD DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df, embedder, resume_index = load_resumes(DATA_CSV)
generator = get_generator(model_choice)

# â”€â”€â”€ USER INPUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("Job Description")
jd = st.text_area("", height=120)

user_resume = None
if uploaded_pdf:
    user_resume = extract_text(uploaded_pdf)
    st.subheader("ğŸ“‘ Uploaded Resume Preview")
    st.write(user_resume[:200] + "...")

# â”€â”€â”€ RUN BUTTON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("Run"):
    if not jd:
        st.error("Please enter a Job Description.")
    else:
        if user_resume:
            score = compute_match_score(jd, user_resume, embedder)
            st.metric("ğŸ“Š Match Score", f"{score*100:.1f}%")

        inds = retrieve_indices(jd, mode, embedder, resume_index)
        st.subheader("ğŸ” Top Existing Resumes")
        for rank, i in enumerate(inds, start=1):
            st.markdown(f"**{rank}. Applicant ID {df.iloc[i]['ID']}**")
            st.write(df.iloc[i]["Resume"][:200] + "â€¦")

        rec = generate_recommendation(jd, inds, df, generator)
        st.subheader("ğŸ¤– Recommendation")
        st.write(rec)